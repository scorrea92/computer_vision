{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 14 17:22:41 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX TIT...  Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "|  0%   44C    P0    60W / 250W |      0MiB / 12205MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/secorec/anaconda3/envs/env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 250, 250, 3)\n",
      "(791,)\n",
      "(784, 250, 250, 3)\n",
      "(784,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70e42e2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization as BN\n",
    "from keras.layers import GaussianNoise as GN\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler as LRS\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 20\n",
    "epochs = 50\n",
    "\n",
    "#### LOAD AND TRANSFORM\n",
    "\n",
    "# ## Download: ONLY ONCE!\n",
    "# !wget https://www.dropbox.com/s/kdhn10jwj99xkv7/data.tgz\n",
    "# !tar xvzf data.tgz\n",
    "# #####\n",
    "\n",
    "\n",
    "# Load \n",
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Stats\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "## View some images\n",
    "plt.imshow(x_train[2,:,:,: ] )\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Transforms\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "## Labels\n",
    "y_train=y_train-1\n",
    "\n",
    "y_test=y_test-1\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 250, 250, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 250, 250, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 250, 250, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 125, 125, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 125, 125, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 125, 125, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 62, 62, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 62, 62, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 62, 62, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 62, 62, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 31, 31, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 31, 31, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 31, 31, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 31, 31, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 31, 31, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 31, 31, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "outer_product (Lambda)          (None, 262144)       0           dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 20)           5242900     outer_product[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12,878,164\n",
      "Trainable params: 5,242,900\n",
      "Non-trainable params: 7,635,264\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "25/24 [==============================] - 15s 591ms/step - loss: 2.9965 - acc: 0.0492 - val_loss: 2.9751 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.97505, saving model to Wehigts.hdf5\n",
      "Epoch 2/50\n",
      "25/24 [==============================] - 10s 416ms/step - loss: 2.9754 - acc: 0.0932 - val_loss: 2.9642 - val_acc: 0.0944\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.97505 to 2.96422, saving model to Wehigts.hdf5\n",
      "Epoch 3/50\n",
      "25/24 [==============================] - 10s 418ms/step - loss: 2.9594 - acc: 0.1132 - val_loss: 2.9537 - val_acc: 0.1339\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.96422 to 2.95373, saving model to Wehigts.hdf5\n",
      "Epoch 4/50\n",
      "25/24 [==============================] - 10s 417ms/step - loss: 2.9471 - acc: 0.1307 - val_loss: 2.9431 - val_acc: 0.1505\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.95373 to 2.94311, saving model to Wehigts.hdf5\n",
      "Epoch 5/50\n",
      "25/24 [==============================] - 10s 418ms/step - loss: 2.9341 - acc: 0.1557 - val_loss: 2.9328 - val_acc: 0.1480\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.94311 to 2.93278, saving model to Wehigts.hdf5\n",
      "Epoch 6/50\n",
      "25/24 [==============================] - 10s 419ms/step - loss: 2.9189 - acc: 0.1465 - val_loss: 2.9226 - val_acc: 0.1518\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.93278 to 2.92256, saving model to Wehigts.hdf5\n",
      "Epoch 7/50\n",
      "25/24 [==============================] - 10s 419ms/step - loss: 2.9074 - acc: 0.1723 - val_loss: 2.9126 - val_acc: 0.1645\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.92256 to 2.91262, saving model to Wehigts.hdf5\n",
      "Epoch 8/50\n",
      "25/24 [==============================] - 10s 418ms/step - loss: 2.8933 - acc: 0.2157 - val_loss: 2.9025 - val_acc: 0.1684\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.91262 to 2.90248, saving model to Wehigts.hdf5\n",
      "Epoch 9/50\n",
      "25/24 [==============================] - 11s 421ms/step - loss: 2.8817 - acc: 0.2210 - val_loss: 2.8925 - val_acc: 0.1875\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.90248 to 2.89250, saving model to Wehigts.hdf5\n",
      "Epoch 10/50\n",
      "25/24 [==============================] - 10s 415ms/step - loss: 2.8676 - acc: 0.2576 - val_loss: 2.8826 - val_acc: 0.1837\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.89250 to 2.88260, saving model to Wehigts.hdf5\n",
      "Epoch 11/50\n",
      "25/24 [==============================] - 11s 423ms/step - loss: 2.8582 - acc: 0.2195 - val_loss: 2.8734 - val_acc: 0.1977\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.88260 to 2.87341, saving model to Wehigts.hdf5\n",
      "Epoch 12/50\n",
      "25/24 [==============================] - 10s 415ms/step - loss: 2.8434 - acc: 0.2542 - val_loss: 2.8643 - val_acc: 0.2066\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.87341 to 2.86426, saving model to Wehigts.hdf5\n",
      "Epoch 13/50\n",
      "25/24 [==============================] - 10s 420ms/step - loss: 2.8323 - acc: 0.2842 - val_loss: 2.8549 - val_acc: 0.1977\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.86426 to 2.85492, saving model to Wehigts.hdf5\n",
      "Epoch 14/50\n",
      "25/24 [==============================] - 10s 416ms/step - loss: 2.8207 - acc: 0.2550 - val_loss: 2.8455 - val_acc: 0.2296\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.85492 to 2.84550, saving model to Wehigts.hdf5\n",
      "Epoch 15/50\n",
      "25/24 [==============================] - 11s 422ms/step - loss: 2.8063 - acc: 0.2823 - val_loss: 2.8365 - val_acc: 0.2334\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.84550 to 2.83647, saving model to Wehigts.hdf5\n",
      "Epoch 16/50\n",
      "25/24 [==============================] - 10s 418ms/step - loss: 2.7964 - acc: 0.2925 - val_loss: 2.8279 - val_acc: 0.2564\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.83647 to 2.82790, saving model to Wehigts.hdf5\n",
      "Epoch 17/50\n",
      "25/24 [==============================] - 10s 420ms/step - loss: 2.7852 - acc: 0.3287 - val_loss: 2.8192 - val_acc: 0.2551\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.82790 to 2.81923, saving model to Wehigts.hdf5\n",
      "Epoch 18/50\n",
      "25/24 [==============================] - 10s 415ms/step - loss: 2.7720 - acc: 0.3048 - val_loss: 2.8098 - val_acc: 0.2615\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.81923 to 2.80983, saving model to Wehigts.hdf5\n",
      "Epoch 19/50\n",
      "25/24 [==============================] - 10s 419ms/step - loss: 2.7613 - acc: 0.3252 - val_loss: 2.8016 - val_acc: 0.2615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss improved from 2.80983 to 2.80158, saving model to Wehigts.hdf5\n",
      "Epoch 20/50\n",
      "25/24 [==============================] - 10s 415ms/step - loss: 2.7499 - acc: 0.3222 - val_loss: 2.7928 - val_acc: 0.2653\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.80158 to 2.79282, saving model to Wehigts.hdf5\n",
      "Epoch 21/50\n",
      "25/24 [==============================] - 10s 414ms/step - loss: 2.7397 - acc: 0.3677 - val_loss: 2.7842 - val_acc: 0.2589\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.79282 to 2.78423, saving model to Wehigts.hdf5\n",
      "Epoch 22/50\n",
      "25/24 [==============================] - 10s 420ms/step - loss: 2.7253 - acc: 0.3878 - val_loss: 2.7758 - val_acc: 0.2717\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.78423 to 2.77582, saving model to Wehigts.hdf5\n",
      "Epoch 23/50\n",
      "25/24 [==============================] - 11s 420ms/step - loss: 2.7162 - acc: 0.3828 - val_loss: 2.7674 - val_acc: 0.2755\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.77582 to 2.76744, saving model to Wehigts.hdf5\n",
      "Epoch 24/50\n",
      "25/24 [==============================] - 11s 420ms/step - loss: 2.7067 - acc: 0.3497 - val_loss: 2.7592 - val_acc: 0.2717\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.76744 to 2.75920, saving model to Wehigts.hdf5\n",
      "Epoch 25/50\n",
      "25/24 [==============================] - 10s 411ms/step - loss: 2.6918 - acc: 0.3858 - val_loss: 2.7509 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.75920 to 2.75091, saving model to Wehigts.hdf5\n",
      "Epoch 26/50\n",
      "25/24 [==============================] - 10s 411ms/step - loss: 2.6805 - acc: 0.4158 - val_loss: 2.7431 - val_acc: 0.2895\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.75091 to 2.74314, saving model to Wehigts.hdf5\n",
      "Epoch 27/50\n",
      "25/24 [==============================] - 10s 411ms/step - loss: 2.6725 - acc: 0.3878 - val_loss: 2.7345 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.74314 to 2.73446, saving model to Wehigts.hdf5\n",
      "Epoch 28/50\n",
      "25/24 [==============================] - 10s 406ms/step - loss: 2.6605 - acc: 0.4011 - val_loss: 2.7269 - val_acc: 0.3023\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.73446 to 2.72694, saving model to Wehigts.hdf5\n",
      "Epoch 29/50\n",
      "25/24 [==============================] - 10s 412ms/step - loss: 2.6506 - acc: 0.4033 - val_loss: 2.7190 - val_acc: 0.2997\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.72694 to 2.71896, saving model to Wehigts.hdf5\n",
      "Epoch 30/50\n",
      "25/24 [==============================] - 10s 407ms/step - loss: 2.6411 - acc: 0.4161 - val_loss: 2.7122 - val_acc: 0.2883\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.71896 to 2.71220, saving model to Wehigts.hdf5\n",
      "Epoch 31/50\n",
      "25/24 [==============================] - 10s 412ms/step - loss: 2.6334 - acc: 0.4207 - val_loss: 2.7037 - val_acc: 0.3074\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.71220 to 2.70371, saving model to Wehigts.hdf5\n",
      "Epoch 32/50\n",
      "25/24 [==============================] - 11s 420ms/step - loss: 2.6193 - acc: 0.4061 - val_loss: 2.6970 - val_acc: 0.3023\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.70371 to 2.69696, saving model to Wehigts.hdf5\n",
      "Epoch 33/50\n",
      "25/24 [==============================] - 10s 412ms/step - loss: 2.6080 - acc: 0.4241 - val_loss: 2.6886 - val_acc: 0.3189\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.69696 to 2.68856, saving model to Wehigts.hdf5\n",
      "Epoch 34/50\n",
      "25/24 [==============================] - 10s 412ms/step - loss: 2.6029 - acc: 0.4114 - val_loss: 2.6807 - val_acc: 0.3099\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.68856 to 2.68073, saving model to Wehigts.hdf5\n",
      "Epoch 35/50\n",
      "25/24 [==============================] - 10s 411ms/step - loss: 2.5938 - acc: 0.4247 - val_loss: 2.6732 - val_acc: 0.3329\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.68073 to 2.67317, saving model to Wehigts.hdf5\n",
      "Epoch 36/50\n",
      "25/24 [==============================] - 10s 408ms/step - loss: 2.5784 - acc: 0.4382 - val_loss: 2.6660 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.67317 to 2.66600, saving model to Wehigts.hdf5\n",
      "Epoch 37/50\n",
      "25/24 [==============================] - 10s 409ms/step - loss: 2.5696 - acc: 0.4535 - val_loss: 2.6591 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.66600 to 2.65908, saving model to Wehigts.hdf5\n",
      "Epoch 38/50\n",
      "25/24 [==============================] - 10s 408ms/step - loss: 2.5609 - acc: 0.4499 - val_loss: 2.6518 - val_acc: 0.3227\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.65908 to 2.65176, saving model to Wehigts.hdf5\n",
      "Epoch 39/50\n",
      "25/24 [==============================] - 10s 408ms/step - loss: 2.5567 - acc: 0.4585 - val_loss: 2.6446 - val_acc: 0.3240\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.65176 to 2.64459, saving model to Wehigts.hdf5\n",
      "Epoch 40/50\n",
      "25/24 [==============================] - 10s 412ms/step - loss: 2.5369 - acc: 0.4710 - val_loss: 2.6377 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.64459 to 2.63775, saving model to Wehigts.hdf5\n",
      "Epoch 41/50\n",
      "25/24 [==============================] - 10s 410ms/step - loss: 2.5362 - acc: 0.4626 - val_loss: 2.6307 - val_acc: 0.3278\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.63775 to 2.63067, saving model to Wehigts.hdf5\n",
      "Epoch 42/50\n",
      "25/24 [==============================] - 10s 412ms/step - loss: 2.5261 - acc: 0.4857 - val_loss: 2.6236 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.63067 to 2.62364, saving model to Wehigts.hdf5\n",
      "Epoch 43/50\n",
      "25/24 [==============================] - 10s 407ms/step - loss: 2.5102 - acc: 0.4960 - val_loss: 2.6171 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.62364 to 2.61711, saving model to Wehigts.hdf5\n",
      "Epoch 44/50\n",
      "25/24 [==============================] - 10s 413ms/step - loss: 2.5101 - acc: 0.4754 - val_loss: 2.6105 - val_acc: 0.3227\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.61711 to 2.61052, saving model to Wehigts.hdf5\n",
      "Epoch 45/50\n",
      "25/24 [==============================] - 10s 408ms/step - loss: 2.4950 - acc: 0.4732 - val_loss: 2.6030 - val_acc: 0.3342\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.61052 to 2.60304, saving model to Wehigts.hdf5\n",
      "Epoch 46/50\n",
      "25/24 [==============================] - 10s 411ms/step - loss: 2.4841 - acc: 0.4785 - val_loss: 2.5969 - val_acc: 0.3342\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.60304 to 2.59691, saving model to Wehigts.hdf5\n",
      "Epoch 47/50\n",
      "25/24 [==============================] - 10s 411ms/step - loss: 2.4794 - acc: 0.4993 - val_loss: 2.5908 - val_acc: 0.3329\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.59691 to 2.59077, saving model to Wehigts.hdf5\n",
      "Epoch 48/50\n",
      "25/24 [==============================] - 11s 421ms/step - loss: 2.4689 - acc: 0.4843 - val_loss: 2.5858 - val_acc: 0.3444\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.59077 to 2.58575, saving model to Wehigts.hdf5\n",
      "Epoch 49/50\n",
      "25/24 [==============================] - 10s 407ms/step - loss: 2.4693 - acc: 0.4758 - val_loss: 2.5787 - val_acc: 0.3431\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.58575 to 2.57871, saving model to Wehigts.hdf5\n",
      "Epoch 50/50\n",
      "25/24 [==============================] - 10s 407ms/step - loss: 2.4568 - acc: 0.4862 - val_loss: 2.5716 - val_acc: 0.3457\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.57871 to 2.57162, saving model to Wehigts.hdf5\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# load the model\n",
    "model1 = VGG16(weights='imagenet', include_top=False, input_shape=x_train.shape[1:])\n",
    "\n",
    "#############################\n",
    "###      BILINEAR        ####\n",
    "#############################\n",
    "\n",
    "# No entrenar la VGG\n",
    "for layer in model1.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "def outer_product(x):\n",
    "  phi_I = tf.einsum('ijkm,ijkn->imn',x[0],x[1])\t\t# Einstein Notation  [batch,1,1,depth] x [batch,1,1,depth] -> [batch,depth,depth]\n",
    "  phi_I = tf.reshape(phi_I,[-1,512*512])\t        # Reshape from [batch_size,depth,depth] to [batch_size, depth*depth]\n",
    "  phi_I = tf.divide(phi_I,31*31)\t\t\t\t\t\t\t\t  # Divide by feature map size [sizexsize]\n",
    "\n",
    "  y_ssqrt = tf.multiply(tf.sign(phi_I),tf.sqrt(tf.abs(phi_I)+1e-12))\t\t# Take signed square root of phi_I\n",
    "  z_l2 = tf.nn.l2_normalize(y_ssqrt, dim=1)\t\t\t\t\t\t\t\t              # Apply l2 normalization\n",
    "  return z_l2\n",
    "\n",
    "\n",
    "\n",
    "conv=model1.get_layer('block4_conv3') # block4_conv3\n",
    "d1=Dropout(0.5)(conv.output)   ## Why??\n",
    "d2=Dropout(0.5)(conv.output)   ## Why??\n",
    "\n",
    "x = Lambda(outer_product, name='outer_product')([d1,d2])\n",
    "predictions=Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#layer_x=Dense(256, activation='relu', name='midle_layer')(x)\n",
    "#predictions=Dense(num_classes, activation='softmax', name='predictions')(layer_x)\n",
    "\n",
    "model = Model(inputs=model1.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# DEFINE A LEARNING RATE SCHEDULER\n",
    "def scheduler(epoch):\n",
    "    if epoch < 25:\n",
    "        return 0.0001\n",
    "    elif epoch < 50:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000001\n",
    "\n",
    "set_lr = LRS(scheduler)\n",
    "\n",
    "\n",
    "## DATAGEN\n",
    "datagen = ImageDataGenerator(\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  rotation_range=20,\n",
    "  zoom_range=[1.0,1.2],\n",
    "  horizontal_flip=True)\n",
    "\n",
    "\n",
    "## OPTIM AND COMPILE use Adam Rsmprop\n",
    "opt = SGD(lr=0.0001, decay=1e-6)\n",
    "rms = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rms,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "  \n",
    "model.summary()\n",
    "\n",
    "checkpoint_path = \"Wehigts.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "\n",
    "## TRAINING with DA and LRA\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
    "                            steps_per_epoch=len(x_train) / batch_size, \n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            callbacks=[checkpointer],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 250, 250, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 250, 250, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 250, 250, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 125, 125, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 125, 125, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 125, 125, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 62, 62, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 62, 62, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 62, 62, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 62, 62, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 31, 31, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 31, 31, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 31, 31, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 31, 31, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 31, 31, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 31, 31, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "outer_product (Lambda)          (None, 262144)       0           dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 20)           5242900     outer_product[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12,878,164\n",
      "Trainable params: 12,878,164\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "25/24 [==============================] - 20s 790ms/step - loss: 0.4804 - acc: 0.8890 - val_loss: 0.9302 - val_acc: 0.7028\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93024, saving model to Wehigts_final.hdf5\n",
      "Epoch 2/50\n",
      "25/24 [==============================] - 19s 753ms/step - loss: 0.2952 - acc: 0.9458 - val_loss: 0.8691 - val_acc: 0.7054\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93024 to 0.86914, saving model to Wehigts_final.hdf5\n",
      "Epoch 3/50\n",
      "25/24 [==============================] - 19s 757ms/step - loss: 0.2605 - acc: 0.9565 - val_loss: 0.9464 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/50\n",
      "25/24 [==============================] - 19s 759ms/step - loss: 0.2508 - acc: 0.9440 - val_loss: 0.8139 - val_acc: 0.7538\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.86914 to 0.81394, saving model to Wehigts_final.hdf5\n",
      "Epoch 5/50\n",
      "25/24 [==============================] - 19s 763ms/step - loss: 0.2073 - acc: 0.9662 - val_loss: 0.9291 - val_acc: 0.6926\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/50\n",
      "25/24 [==============================] - 20s 781ms/step - loss: 0.1905 - acc: 0.9687 - val_loss: 0.8486 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.1984 - acc: 0.9503 - val_loss: 0.8494 - val_acc: 0.7334\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.1527 - acc: 0.9698 - val_loss: 0.9461 - val_acc: 0.7181\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.1530 - acc: 0.9708 - val_loss: 0.8652 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.1215 - acc: 0.9745 - val_loss: 0.9740 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/50\n",
      "25/24 [==============================] - 19s 776ms/step - loss: 0.1399 - acc: 0.9700 - val_loss: 0.8735 - val_acc: 0.7309\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/50\n",
      "25/24 [==============================] - 19s 776ms/step - loss: 0.1020 - acc: 0.9750 - val_loss: 0.9253 - val_acc: 0.7245\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0704 - acc: 0.9900 - val_loss: 1.3678 - val_acc: 0.6339\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/50\n",
      "25/24 [==============================] - 19s 775ms/step - loss: 0.1070 - acc: 0.9775 - val_loss: 0.8930 - val_acc: 0.7526\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0994 - acc: 0.9803 - val_loss: 1.0338 - val_acc: 0.6901\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0884 - acc: 0.9800 - val_loss: 1.0753 - val_acc: 0.6735\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0722 - acc: 0.9850 - val_loss: 1.0844 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0862 - acc: 0.9800 - val_loss: 1.0449 - val_acc: 0.6964\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.1245 - acc: 0.9675 - val_loss: 0.9194 - val_acc: 0.7321\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/50\n",
      "25/24 [==============================] - 20s 787ms/step - loss: 0.0526 - acc: 0.9858 - val_loss: 1.3824 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0517 - acc: 0.9850 - val_loss: 1.1712 - val_acc: 0.6633\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/50\n",
      "25/24 [==============================] - 19s 775ms/step - loss: 0.0716 - acc: 0.9862 - val_loss: 1.0186 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0584 - acc: 0.9837 - val_loss: 1.0126 - val_acc: 0.7372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0897 - acc: 0.9740 - val_loss: 0.9107 - val_acc: 0.7564\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/50\n",
      "25/24 [==============================] - 19s 775ms/step - loss: 0.0647 - acc: 0.9858 - val_loss: 0.8978 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/50\n",
      "25/24 [==============================] - 19s 775ms/step - loss: 0.0663 - acc: 0.9841 - val_loss: 1.0469 - val_acc: 0.7258\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0709 - acc: 0.9787 - val_loss: 1.9111 - val_acc: 0.5383\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0777 - acc: 0.9798 - val_loss: 1.0004 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0771 - acc: 0.9740 - val_loss: 1.0023 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0308 - acc: 0.9887 - val_loss: 1.1707 - val_acc: 0.7003\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.1019 - acc: 0.9712 - val_loss: 1.0366 - val_acc: 0.7360\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0956 - acc: 0.9700 - val_loss: 0.9953 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0377 - acc: 0.9875 - val_loss: 1.1121 - val_acc: 0.7079\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0525 - acc: 0.9808 - val_loss: 1.1509 - val_acc: 0.7054\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/50\n",
      "25/24 [==============================] - 19s 771ms/step - loss: 0.0364 - acc: 0.9883 - val_loss: 1.0795 - val_acc: 0.7347\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0303 - acc: 0.9920 - val_loss: 1.1430 - val_acc: 0.7181\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0469 - acc: 0.9925 - val_loss: 1.0465 - val_acc: 0.7436\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0750 - acc: 0.9808 - val_loss: 1.1000 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.9981 - val_acc: 0.7462\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0473 - acc: 0.9850 - val_loss: 1.0181 - val_acc: 0.7321\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0500 - acc: 0.9825 - val_loss: 1.0746 - val_acc: 0.7398\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0368 - acc: 0.9887 - val_loss: 1.0489 - val_acc: 0.7334\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.1246 - acc: 0.9708 - val_loss: 2.6419 - val_acc: 0.4247\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0732 - acc: 0.9762 - val_loss: 1.1057 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0543 - acc: 0.9795 - val_loss: 1.8250 - val_acc: 0.6033\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0682 - acc: 0.9740 - val_loss: 1.2599 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0667 - acc: 0.9808 - val_loss: 1.1237 - val_acc: 0.7168\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/50\n",
      "25/24 [==============================] - 19s 773ms/step - loss: 0.0748 - acc: 0.9750 - val_loss: 2.1621 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/50\n",
      "25/24 [==============================] - 19s 772ms/step - loss: 0.0587 - acc: 0.9845 - val_loss: 1.1294 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/50\n",
      "25/24 [==============================] - 19s 774ms/step - loss: 0.0197 - acc: 0.9937 - val_loss: 1.0704 - val_acc: 0.7526\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "#Usar Checpoint mejor de ejecución\n",
    "model.load_weights(checkpoint_path)\n",
    "for j, layer in enumerate(model1.layers):\n",
    "    layer.trainable = True\n",
    "    #if j <14:\n",
    "    #    if \"conv\" in layer.name:\n",
    "    #        layer.trainable = True\n",
    "            \n",
    "#Compile y ejecutar de nuevo\n",
    "#rms = RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rms,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "  \n",
    "model.summary()\n",
    "\n",
    "checkpoint_path = \"Wehigts_final.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "\n",
    "## TRAINING with DA and LRA\n",
    "history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
    "                            steps_per_epoch=len(x_train) / batch_size, \n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            callbacks=[checkpointer],\n",
    "                            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
